{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML_Project (1).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V2EGDShSFwFX",
        "colab_type": "text"
      },
      "source": [
        "Importing necessary Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UL9qOyvq6tLH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import Perceptron\n",
        "from sklearn.neighbors import KNeighborsClassifier\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c21yJKWPDdeE",
        "colab_type": "text"
      },
      "source": [
        "Loading Read the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TCTmQyZC6vsE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = pd.read_csv(\"messidor_features.csv\",names=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20])\n",
        "\n",
        "X = dataset.drop(20, axis=1)\n",
        "y = dataset[20]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EMIIPbRfGCuh",
        "colab_type": "text"
      },
      "source": [
        "Splitting Training and Testing Data(80-20)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BrQhHvFH7D4D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WEDF20jdGNfi",
        "colab_type": "text"
      },
      "source": [
        "Logistic Regression Implementation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Si2Doc7o7PJQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def lin_reg(X_train, y_train,X_test):\n",
        "  log_regressor = LogisticRegression(max_iter=2500)\n",
        "  log_regressor.fit(X_train, y_train)\n",
        "  p=log_regressor.predict(X_test)\n",
        "  q=log_regressor.predict(X_train)\n",
        "  print(confusion_matrix(y_test, p, labels=None, sample_weight=None, normalize=None))\n",
        "  #print(confusion_matrix(y_train, q, labels=None, sample_weight=None, normalize=None))\n",
        "  return p,q"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l-2Aa0z_GSe4",
        "colab_type": "text"
      },
      "source": [
        "Random Forest Implementation "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MEguW9ek7ZsV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def RF(X_train, y_train,X_test):\n",
        "\n",
        "  from sklearn.ensemble import RandomForestClassifier\n",
        "  rf = RandomForestClassifier()\n",
        "  rf.fit(X_train, y_train) \n",
        "  p=rf.predict(X_test)\n",
        "  q=rf.predict(X_train)\n",
        "  print(confusion_matrix(y_test, p, labels=None, sample_weight=None, normalize=None))\n",
        "  #print(confusion_matrix(y_train, q, labels=None, sample_weight=None, normalize=None))\n",
        "  return p,q"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tqGL0tXEGwmk",
        "colab_type": "text"
      },
      "source": [
        "Naive Bayes Implementation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "md62NufjZHNn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def NB(X_train, y_train,X_test):\n",
        "  gnb = GaussianNB()\n",
        "  gnb = gnb.fit(X_train, y_train)\n",
        "  p=gnb.predict(X_test)\n",
        "  q=gnb.predict(X_train)\n",
        "  print(confusion_matrix(y_test, p, labels=None, sample_weight=None, normalize=None))\n",
        "  #print(confusion_matrix(y_train, q, labels=None, sample_weight=None, normalize=None))\n",
        "  return p,q"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-F0yeisRZmAc",
        "colab_type": "text"
      },
      "source": [
        "Perceptron Implementation:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g1t6S2gSQ7gX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def perceptron(X_train, y_train,X_test):\n",
        "  rf = Perceptron()\n",
        "  rf.fit(X_train, y_train) \n",
        "  p=rf.predict(X_test)\n",
        "  print(confusion_matrix(y_test, p, labels=None, sample_weight=None, normalize=None))\n",
        "  q = rf.predict(X_train)\n",
        "  return p,q"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZbQrpy8cHT08",
        "colab_type": "text"
      },
      "source": [
        "MultiLayer Perceptron Implementation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1K-gu3dZ7ijx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def MLP(X_train, y_train,X_test):\n",
        " \n",
        "  from sklearn.neural_network import MLPClassifier\n",
        "  clf = MLPClassifier(solver='adam',activation='tanh',alpha=1e-5,max_iter=20000,hidden_layer_sizes=(10,5))\n",
        "  clf.fit(X, y)\n",
        "  p = clf.predict(X_test)\n",
        "  q = clf.predict(X_train)\n",
        "  print(confusion_matrix(y_test, p, labels=None, sample_weight=None, normalize=None))\n",
        "  #print(confusion_matrix(y_train, q, labels=None, sample_weight=None, normalize=None))\n",
        "  return p,q"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iMjwrVvIHgOW",
        "colab_type": "text"
      },
      "source": [
        "Support Vector Machine Implementation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QrZrJ7pz7i5R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def SVM(X_train, y_train,X_test):\n",
        "\n",
        "  from sklearn.svm import SVC\n",
        "  clf = SVC(gamma='auto')\n",
        "  clf.fit(X_train, y_train)\n",
        "  p = clf.predict(X_test)\n",
        "  q = clf.predict(X_train)\n",
        "  print(confusion_matrix(y_test, p, labels=None, sample_weight=None, normalize=None))\n",
        "  #print(confusion_matrix(y_train, q, labels=None, sample_weight=None, normalize=None))\n",
        "  return p,q"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rA_eVUb2HqyJ",
        "colab_type": "text"
      },
      "source": [
        "Radial Basis Function Implementation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mCQwd7bN8nuv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def RBF(X_train, y_train,X_test):\n",
        "\n",
        "  from sklearn.svm import SVC\n",
        "  clf = SVC(gamma='auto',kernel='rbf')\n",
        "  clf.fit(X_train, y_train)\n",
        "  p = clf.predict(X_test)\n",
        "  q = clf.predict(X_train)\n",
        "  print(confusion_matrix(y_test, p, labels=None, sample_weight=None, normalize=None))\n",
        "  #print(confusion_matrix(y_train, q, labels=None, sample_weight=None, normalize=None))\n",
        "  return p,q"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yH72sQ9_H0cK",
        "colab_type": "text"
      },
      "source": [
        "Decision Forest Implementation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SAl7ti5n7k87",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def DT(X_train, y_train,X_test):\n",
        "\n",
        "  dt = DecisionTreeClassifier()\n",
        "  dt.fit(X_train,y_train)\n",
        "  p = dt.predict(X_test)\n",
        "  q = dt.predict(X_train)\n",
        "  print(confusion_matrix(y_test, p, labels=None, sample_weight=None, normalize=None))\n",
        "  #print(confusion_matrix(y_train, q, labels=None, sample_weight=None, normalize=None))\n",
        "  return p,q"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1aP9rl7JZwCz",
        "colab_type": "text"
      },
      "source": [
        "K Neighbors Classifier Implementation:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eM6OIjf5UyIY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def KNN(X_train, y_train,X_test):\n",
        "\n",
        "  dt = KNeighborsClassifier()\n",
        "  dt.fit(X_train,y_train)\n",
        "  p = dt.predict(X_test)\n",
        "  q = dt.predict(X_train)\n",
        "  print(confusion_matrix(y_test, p, labels=None, sample_weight=None, normalize=None))\n",
        "  #print(confusion_matrix(y_train, q, labels=None, sample_weight=None, normalize=None))\n",
        "  return p,q"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TYXfKhtYH6KA",
        "colab_type": "text"
      },
      "source": [
        "Measuring Accuracy "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hWTUBrys7mgE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "def accuracy(y_test,y_train,p,q):\n",
        "\n",
        "  print(\"Accuracy: \",accuracy_score(y_test, p))\n",
        "  print(\"Precision: \",precision_score(y_test, p))\n",
        "  print(\"Recall: \",recall_score(y_test, p))\n",
        "  print(\"F1 Score: \",f1_score(y_test, p))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lirnaViVH91d",
        "colab_type": "text"
      },
      "source": [
        "Normalising the data "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0b1s1TOe7sBe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "x = scaler.fit_transform(X)\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.20)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bBLM4UXgIBlT",
        "colab_type": "text"
      },
      "source": [
        "Training and Testing the models with UnNormalized Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JLoAcLFT7yg4",
        "colab_type": "code",
        "outputId": "6a7743b7-4060-4929-a041-35e982c19d8c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "X = dataset.drop(20, axis=1)\n",
        "y = dataset[20]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)\n",
        "\n",
        "print(\"UnNormalized Data:\")\n",
        "print()\n",
        "\n",
        "print(\"logistic Regression: \")\n",
        "p,q = lin_reg(X_train, y_train,X_test)\n",
        "accuracy(y_test,y_train,p,q)\n",
        "print()\n",
        "\n",
        "print(\"Naive Bayes: \")\n",
        "p,q = NB(X_train, y_train,X_test)\n",
        "accuracy(y_test,y_train,p,q)\n",
        "#print(classification_report(y_test, p))\n",
        "print()\n",
        "\n",
        "print(\"Radial Basis Function: \")\n",
        "p,q = RBF(X_train, y_train,X_test)\n",
        "accuracy(y_test,y_train,p,q)\n",
        "#print(classification_report(y_test, p))\n",
        "print()\n",
        "\n",
        "print(\"Support Vector Machine: \")\n",
        "p,q = SVM(X_train, y_train,X_test)\n",
        "accuracy(y_test,y_train,p,q)\n",
        "#print(classification_report(y_test, p))\n",
        "print()\n",
        "\n",
        "print(\"Multi Layer Perceptron: \")\n",
        "p,q = MLP(X_train, y_train,X_test)\n",
        "accuracy(y_test,y_train,p,q)\n",
        "#print(classification_report(y_test, p))\n",
        "print()\n",
        "\n",
        "print(\"Random Forest: \")\n",
        "p,q = RF(X_train, y_train,X_test)\n",
        "accuracy(y_test,y_train,p,q)\n",
        "print()\n",
        "\n",
        "print(\"Decision Tree: \")\n",
        "p,q = DT(X_train, y_train,X_test)\n",
        "accuracy(y_test,y_train,p,q)\n",
        "print()\n",
        "\n",
        "print(\"Perceptron: \")\n",
        "p,q = perceptron(X_train, y_train,X_test)\n",
        "accuracy(y_test,y_train,p,q)\n",
        "print()\n",
        "\n",
        "print(\"KNN: \")\n",
        "p,q = KNN(X_train, y_train,X_test)\n",
        "accuracy(y_test,y_train,p,q)\n",
        "print()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "UnNormalized Data:\n",
            "\n",
            "logistic Regression: \n",
            "[[87 17]\n",
            " [46 81]]\n",
            "Accuracy:  0.7272727272727273\n",
            "Precision:  0.826530612244898\n",
            "Recall:  0.6377952755905512\n",
            "F1 Score:  0.72\n",
            "\n",
            "Naive Bayes: \n",
            "[[99  5]\n",
            " [94 33]]\n",
            "Accuracy:  0.5714285714285714\n",
            "Precision:  0.868421052631579\n",
            "Recall:  0.25984251968503935\n",
            "F1 Score:  0.39999999999999997\n",
            "\n",
            "Radial Basis Function: \n",
            "[[ 33  71]\n",
            " [ 26 101]]\n",
            "Accuracy:  0.5800865800865801\n",
            "Precision:  0.5872093023255814\n",
            "Recall:  0.7952755905511811\n",
            "F1 Score:  0.6755852842809366\n",
            "\n",
            "Support Vector Machine: \n",
            "[[ 33  71]\n",
            " [ 26 101]]\n",
            "Accuracy:  0.5800865800865801\n",
            "Precision:  0.5872093023255814\n",
            "Recall:  0.7952755905511811\n",
            "F1 Score:  0.6755852842809366\n",
            "\n",
            "Multi Layer Perceptron: \n",
            "[[91 13]\n",
            " [38 89]]\n",
            "Accuracy:  0.7792207792207793\n",
            "Precision:  0.8725490196078431\n",
            "Recall:  0.7007874015748031\n",
            "F1 Score:  0.777292576419214\n",
            "\n",
            "Random Forest: \n",
            "[[69 35]\n",
            " [48 79]]\n",
            "Accuracy:  0.6406926406926406\n",
            "Precision:  0.6929824561403509\n",
            "Recall:  0.6220472440944882\n",
            "F1 Score:  0.6556016597510375\n",
            "\n",
            "Decision Tree: \n",
            "[[65 39]\n",
            " [49 78]]\n",
            "Accuracy:  0.6190476190476191\n",
            "Precision:  0.6666666666666666\n",
            "Recall:  0.6141732283464567\n",
            "F1 Score:  0.6393442622950819\n",
            "\n",
            "Perceptron: \n",
            "[[96  8]\n",
            " [68 59]]\n",
            "Accuracy:  0.670995670995671\n",
            "Precision:  0.8805970149253731\n",
            "Recall:  0.4645669291338583\n",
            "F1 Score:  0.6082474226804124\n",
            "\n",
            "KNN: \n",
            "[[74 30]\n",
            " [48 79]]\n",
            "Accuracy:  0.6623376623376623\n",
            "Precision:  0.7247706422018348\n",
            "Recall:  0.6220472440944882\n",
            "F1 Score:  0.6694915254237287\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AAbFcDAkIgTh",
        "colab_type": "text"
      },
      "source": [
        "Training and Testing the models with Normalised Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CAIQd_Y5TVWC",
        "colab_type": "code",
        "outputId": "fddbfacd-7be1-4906-9699-6a2da3b0080d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "import pandas\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import model_selection\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "\n",
        "dataset = pd.read_csv(\"messidor_features.csv\",names=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20])\n",
        "\n",
        "array = dataset.values\n",
        "X = array[:,0:19]\n",
        "Y = array[:,19]\n",
        "# prepare configuration for cross validation test harness\n",
        "seed = 7\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "# prepare models\n",
        "models = []\n",
        "models.append(('LR', LogisticRegression(max_iter=1500)))\n",
        "models.append(('KNN', KNeighborsClassifier()))\n",
        "\n",
        "models.append(('NB', GaussianNB()))\n",
        "models.append(('RBF', SVC(kernel='rbf')))\n",
        "models.append(('SVM', SVC()))\n",
        "#models=[]\n",
        "models.append(('CART', DecisionTreeClassifier()))\n",
        "models.append(('Random Forest',RandomForestClassifier()))\n",
        "models.append(('Perceptron',Perceptron()))\n",
        "models.append(('MLP',MLPClassifier(solver='adam',activation='logistic',alpha=1e-5,max_iter=20000,hidden_layer_sizes=(10,5,2))))\n",
        "# evaluate each model in turn\n",
        "results = []\n",
        "names = []\n",
        "scoring = 'accuracy'\n",
        "for name, model in models:\n",
        "\tkfold = model_selection.KFold(n_splits=10)\n",
        "\tcv_results = model_selection.cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n",
        "\tresults.append(cv_results)\n",
        "\tnames.append(name)\n",
        "\tmsg = \"%s: %f \" % (name,max(cv_results))\n",
        "\tprint(msg)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LR: 0.791304 \n",
            "KNN: 0.713043 \n",
            "NB: 0.686957 \n",
            "RBF: 0.791304 \n",
            "SVM: 0.791304 \n",
            "CART: 0.678261 \n",
            "Random Forest: 0.741379 \n",
            "Perceptron: 0.695652 \n",
            "MLP: 0.800000 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zro0jEOOaJ12",
        "colab_type": "text"
      },
      "source": [
        "Principal Component Analysis:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YAJv3a_rbGJ7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.decomposition import PCA\n",
        "pca = PCA(n_components=10)\n",
        "xr=pca.fit_transform(X,y)\n",
        "array = dataset.values\n",
        "X = xr\n",
        "y = array[:,19]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2oecpJlPaN5O",
        "colab_type": "text"
      },
      "source": [
        "Training and Testing the models with Dimensionality reduced data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "59Rr69x3RJvp",
        "colab_type": "code",
        "outputId": "40d653b2-f861-4645-d148-40d6043e3ed0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "print(\"Dimensionality Reduced Data:(Using PCA)\")\n",
        "\n",
        "p,q = lin_reg(X_train, y_train,X_test)\n",
        "ta,acc = accuracy(y_test,y_train,p,q)\n",
        "print(\"logistic Regression: \",ta,acc)\n",
        "\n",
        "p,q = NB(X_train, y_train,X_test)\n",
        "ta,acc = accuracy(y_test,y_train,p,q)\n",
        "print(\"Naive Bayes: \",ta,acc)\n",
        "#print(classification_report(y_test, p))\n",
        "\n",
        "p,q = RBF(X_train, y_train,X_test)\n",
        "ta,acc = accuracy(y_test,y_train,p,q)\n",
        "print(\"Radial Basis Function: \",ta,acc)\n",
        "#print(classification_report(y_test, p))\n",
        "\n",
        "p,q = SVM(X_train, y_train,X_test)\n",
        "ta,acc = accuracy(y_test,y_train,p,q)\n",
        "print(\"Support Vector Machine: \",ta,acc)\n",
        "#print(classification_report(y_test, p))\n",
        "\n",
        "p,q = MLP(X_train, y_train,X_test)\n",
        "ta,acc = accuracy(y_test,y_train,p,q)\n",
        "print(\"Multi Layer Perceptron: \",ta,acc)\n",
        "#print(classification_report(y_test, p))\n",
        "\n",
        "p,q = RF(X_train, y_train,X_test)\n",
        "ta,acc = accuracy(y_test,y_train,p,q)\n",
        "print(\"Random Forest: \",ta,acc)\n",
        "\n",
        "p,q = DT(X_train, y_train,X_test)\n",
        "ta,acc = accuracy(y_test,y_train,p,q)\n",
        "print(\"Decision Tree: \",ta,acc)\n",
        "\n",
        "p,q = perceptron(X_train, y_train,X_test)\n",
        "ta,acc = accuracy(y_test,y_train,p,q)\n",
        "print(\"Perceptron: \",ta,acc)\n",
        "\n",
        "p,q = KNN(X_train, y_train,X_test)\n",
        "ta,acc = accuracy(y_test,y_train,p,q)\n",
        "print(\"KNN: \",ta,acc)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dimensionality Reduced Data(using PCA):\n",
            "\n",
            "logistic Regression: \n",
            "[[82 25]\n",
            " [42 82]]\n",
            "Accuracy:  0.70995670995671\n",
            "Precision:  0.7663551401869159\n",
            "Recall:  0.6612903225806451\n",
            "F1 Score:  0.70995670995671\n",
            "\n",
            "Naive Bayes: \n",
            "[[101   6]\n",
            " [ 97  27]]\n",
            "Accuracy:  0.5541125541125541\n",
            "Precision:  0.8181818181818182\n",
            "Recall:  0.21774193548387097\n",
            "F1 Score:  0.3439490445859873\n",
            "\n",
            "Radial Basis Function: \n",
            "[[ 25  82]\n",
            " [ 18 106]]\n",
            "Accuracy:  0.5670995670995671\n",
            "Precision:  0.5638297872340425\n",
            "Recall:  0.8548387096774194\n",
            "F1 Score:  0.6794871794871794\n",
            "\n",
            "Support Vector Machine: \n",
            "[[ 25  82]\n",
            " [ 18 106]]\n",
            "Accuracy:  0.5670995670995671\n",
            "Precision:  0.5638297872340425\n",
            "Recall:  0.8548387096774194\n",
            "F1 Score:  0.6794871794871794\n",
            "\n",
            "Multi Layer Perceptron: \n",
            "[[79 28]\n",
            " [37 87]]\n",
            "Accuracy:  0.7186147186147186\n",
            "Precision:  0.7565217391304347\n",
            "Recall:  0.7016129032258065\n",
            "F1 Score:  0.7280334728033472\n",
            "\n",
            "Random Forest: \n",
            "[[74 33]\n",
            " [54 70]]\n",
            "Accuracy:  0.6233766233766234\n",
            "Precision:  0.6796116504854369\n",
            "Recall:  0.5645161290322581\n",
            "F1 Score:  0.616740088105727\n",
            "\n",
            "Decision Tree: \n",
            "[[65 42]\n",
            " [51 73]]\n",
            "Accuracy:  0.5974025974025974\n",
            "Precision:  0.6347826086956522\n",
            "Recall:  0.5887096774193549\n",
            "F1 Score:  0.6108786610878661\n",
            "\n",
            "Perceptron: \n",
            "Accuracy:  0.5844155844155844\n",
            "Precision:  0.5660377358490566\n",
            "Recall:  0.967741935483871\n",
            "F1 Score:  0.7142857142857144\n",
            "\n",
            "KNN: \n",
            "[[72 35]\n",
            " [47 77]]\n",
            "Accuracy:  0.645021645021645\n",
            "Precision:  0.6875\n",
            "Recall:  0.6209677419354839\n",
            "F1 Score:  0.6525423728813559\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}